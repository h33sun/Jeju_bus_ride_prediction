{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "\n",
    "# 분석을 위해 컬럼명 수정\n",
    "train.rename(columns={'6~7_ride': 'ride6', '7~8_ride': 'ride7', '8~9_ride': 'ride8',\\\n",
    "                      '9~10_ride': 'ride9', '10~11_ride': 'ride10', '11~12_ride': 'ride11', \n",
    "                      '6~7_takeoff': 'off6', '7~8_takeoff': 'off7', '8~9_takeoff': 'off8', \\\n",
    "                      '9~10_takeoff': 'off9', '10~11_takeoff': 'off10', '11~12_takeoff': 'off11',\\\n",
    "                      '18~20_ride': 'ride18'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 변수 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weekday\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weekend\n",
    "train['weekend']=[1 if date>=5 else 0 for date in train['weekday']]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thanksgiving_Day\n",
    "train['Thanksgiving_Day'] = 0\n",
    "train.loc[train['date'] == '2019-09-14', 'Thanksgiving_Day'] = 1\n",
    "train.loc[train['date'] == '2019-09-13', 'Thanksgiving_Day'] = 1\n",
    "train.loc[train['date'] == '2019-09-12', 'Thanksgiving_Day'] = 1\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위치\n",
    "jeju_addr=pd.read_csv('jeju_addr.csv')\n",
    "train = pd.merge(train, jeju_addr, on= 'station_code')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2시간 단위 컬럼 생성\n",
    "train['ride68']=train['ride6']+train['ride7'] # 6 ~ 8시 승차인원\n",
    "train['ride810']=train['ride8']+train['ride9']\n",
    "train['ride1012']=train['ride10']+train['ride11']\n",
    "\n",
    "train['off68']=train['off6']+train['off7'] # 6 ~ 8시 하차인원\n",
    "train['off810']=train['off8']+train['off9']\n",
    "train['off1012']=train['off10']+train['off11']\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather 데이터를 추가하기 전 실행해주세요!\n",
    "jeju=['제주시','애월읍','조천읍']\n",
    "seogipo=['서귀포시','남원읍','안덕면']\n",
    "sungsan=['성산읍','구좌읍','우도면','표선면']\n",
    "gosan=['한경면','한림읍','대정읍']\n",
    "chuga=['추자면']\n",
    "weather_addr=[]\n",
    "for city in train['city']:\n",
    "    if city in jeju: weather_addr.append('제주')\n",
    "    elif city in seogipo: weather_addr.append('서귀포')\n",
    "    elif city in gosan : weather_addr.append('고산')\n",
    "    elif city in sungsan : weather_addr.append('성산')\n",
    "    elif city in chuga : weather_addr.append('추자')    \n",
    "#weather_addr 컬럼 생성\n",
    "train['weather_addr']=weather_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 38)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weather 변수 추가\n",
    "weather=pd.read_excel('all_weather.xlsx')\n",
    "train = pd.merge(train, weather, on= ['weather_addr','date'])\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>bus_route_id</th>\n",
       "      <th>in_out</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>ride6</th>\n",
       "      <th>ride7</th>\n",
       "      <th>...</th>\n",
       "      <th>ride68</th>\n",
       "      <th>ride810</th>\n",
       "      <th>ride1012</th>\n",
       "      <th>off68</th>\n",
       "      <th>off810</th>\n",
       "      <th>off1012</th>\n",
       "      <th>weather_addr</th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>bus_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>415421</td>\n",
       "      <td>294340</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>31590000</td>\n",
       "      <td>시내</td>\n",
       "      <td>2740</td>\n",
       "      <td>하모체육공원</td>\n",
       "      <td>33.21875</td>\n",
       "      <td>126.25229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>고산</td>\n",
       "      <td>20.5</td>\n",
       "      <td>34.1</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415422</td>\n",
       "      <td>292357</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>27700000</td>\n",
       "      <td>시내</td>\n",
       "      <td>4122</td>\n",
       "      <td>붉으내</td>\n",
       "      <td>33.31893</td>\n",
       "      <td>126.17250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>고산</td>\n",
       "      <td>20.5</td>\n",
       "      <td>34.1</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       date  bus_route_id in_out  station_code station_name  \\\n",
       "415421  294340 2019-09-22      31590000     시내          2740       하모체육공원   \n",
       "415422  292357 2019-09-22      27700000     시내          4122          붉으내   \n",
       "\n",
       "        latitude  longitude  ride6  ride7  ...  ride68  ride810  ride1012  \\\n",
       "415421  33.21875  126.25229    0.0    0.0  ...     0.0      0.0       0.0   \n",
       "415422  33.31893  126.17250    1.0    0.0  ...     1.0      0.0       0.0   \n",
       "\n",
       "        off68  off810  off1012  weather_addr  temperature  precipitation  \\\n",
       "415421    0.0     0.0      1.0            고산         20.5           34.1   \n",
       "415422    0.0     0.0      0.0            고산         20.5           34.1   \n",
       "\n",
       "        bus_interval  \n",
       "415421          67.0  \n",
       "415422          94.0  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bus_interval 변수 추가\n",
    "#'bus_interval'컬럼에서 na값을 가지는 행들을 분석해본 결과, 대부분 18~20시의 탑승 인원이 거의 없는 bus_route_id 와 station_code 였다. \n",
    "# 따라서 탑승 인원이 별로 없을 것이라고 예상되는 버스는 배차 간격이 길 것이라고 판단하여 na값을 '9999' 로 채워주었다.\n",
    "bus_interval=pd.read_csv('bus_interval_final.csv')\n",
    "train = pd.merge(train, bus_interval, on='bus_route_id',how='left')\n",
    "train['bus_interval'] = train['bus_interval'].fillna(9999)\n",
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415423, 39)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 함수추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test에만 있고 train에는 없는 정류장들을 train에 복제하기\n",
    "def staion_copy_to_train(hi):\n",
    "    hi_train = hi[hi['date']  <= '2019-09-21']\n",
    "    hi_test = hi[hi['date']  >= '2019-09-22']\n",
    "    \n",
    "    set1=set(hi_train.station_code)\n",
    "    set2=set(hi_test.station_code)\n",
    "    te_minus_tr=set2-set1\n",
    "    \n",
    "    idx=[]\n",
    "    idx_1_df=pd.DataFrame()\n",
    "    for num in te_minus_tr:\n",
    "        idx=list(hi[hi[\"station_code\"] == num].id)\n",
    "        for i in idx:\n",
    "            idx_1_df=idx_1_df.append(hi[hi['id']==i])\n",
    "    hi_train=pd.concat([hi_train,idx_1_df])   \n",
    "    return hi_train,hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test에만 있고 train에는 없는 노선들을 train,test에 8:2비율로 나누기\n",
    "\n",
    "def test_minus_train(hi):\n",
    "    hi_train,hi_test=staion_copy_to_train(hi)\n",
    "    \n",
    "    #test에만 있고 train에는 없는 노선번호들\n",
    "    set1=set(hi_train.bus_route_id)\n",
    "    set2=set(hi_test.bus_route_id)\n",
    "    te_minus_tr=set2-set1\n",
    "    \n",
    "    # test set에서 bus_route_id가 te_minus_tr인 애들 지우기\n",
    "    # mask 씌울 항목 선정 \n",
    "    mask = hi_test['bus_route_id'].isin(te_minus_tr) \n",
    "    hi_test=hi_test[~mask] \n",
    "\n",
    "    # 정류소별로 테스트와 나누기\n",
    "    # 빈 리스트 2개를 만들\n",
    "    ids_1_df=pd.DataFrame()\n",
    "    ids_2_df=pd.DataFrame()\n",
    "    \n",
    "    for num in te_minus_tr:\n",
    "        ids = list(hi[hi[\"bus_route_id\"] == num].id)\n",
    "        # ids (8:2 수준)\n",
    "        ids_1 = np.random.choice(ids, int(len(ids) *0.7), replace=False)\n",
    "        ids_2=list(set(ids)-set(ids_1))\n",
    "\n",
    "        # 데이터프레임생성\n",
    "        for i in ids_1:\n",
    "            ids_1_df=ids_1_df.append(hi[hi['id']==i])\n",
    "        for i in ids_2:\n",
    "            ids_2_df=ids_2_df.append(hi[hi['id']==i])\n",
    "        \n",
    "    hi_train=pd.concat([hi_train,ids_1_df])\n",
    "    hi_test=pd.concat([hi_test,ids_2_df])\n",
    "    \n",
    "    return hi_train,hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#같은 station_code를 공유하는 train,test 에서 test에만 있는 bus_route_id를 train에 복제하기\n",
    "def route_copy_to_train(hi):\n",
    "    hi_train,hi_test=test_minus_train(hi)\n",
    "    #같은 station_code를 공유하는 train,test의 bus_route_id 들을 확인하는 데이터프레임 생성\n",
    "    a=pd.DataFrame(hi_train.groupby('station_code')['bus_route_id'].unique()).reset_index()\n",
    "    b=pd.DataFrame(hi_test.groupby('station_code')['bus_route_id'].unique()).reset_index()\n",
    "    merged=pd.merge(a,b,how='outer',on='station_code').rename(columns={'bus_route_id_x':'bus_route_id_train','bus_route_id_y':'bus_route_id_test'})\n",
    "\n",
    "    #같은 station_code에서, test에는 있고 train에는 없는 bus_route_id의 [station_code,bus_route_id] 반환\n",
    "    dics=[]\n",
    "    staion=[]\n",
    "    for i in range(len(merged)):\n",
    "        try:\n",
    "            ls=list(set(merged['bus_route_id_test'][i])-set(merged['bus_route_id_train'][i]))\n",
    "            station=merged['station_code'][i]\n",
    "            if len(ls)>0:\n",
    "                dic=[station,ls]\n",
    "                dics.append(dic)\n",
    "        except:\n",
    "            dics=dics\n",
    "    \n",
    "    #dics의 [station_code,bus_route_id]를 가진 test 데이터들을 train에 복제\n",
    "    copy_df=pd.DataFrame()\n",
    "    for i in range(len(dics)) :\n",
    "        station=dics[i][0]\n",
    "        route_id=dics[i][1]\n",
    "        df=hi_test[(hi_test['station_code']==station) & (hi_test['bus_route_id'].isin(route_id))]\n",
    "        copy_df=pd.concat([copy_df,df])\n",
    "    hi_train=pd.concat([hi_train,copy_df])\n",
    "    return hi_train,hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#같은 station_code를 공유하는 train,test 에서 test에만 있는 weekday를 train에 복제하기\n",
    "def weekday_copy_to_train(hi):\n",
    "    hi_train,hi_test=test_minus_train(hi)\n",
    "    #같은 station_code를 공유하는 train,test의 weekday 들을 확인하는 데이터프레임 생성\n",
    "    a=pd.DataFrame(hi_train.groupby('station_code')['weekday'].unique()).reset_index()\n",
    "    b=pd.DataFrame(hi_test.groupby('station_code')['weekday'].unique()).reset_index()\n",
    "    merged=pd.merge(a,b,how='outer',on='station_code').rename(columns={'weekday_x':'weekday_train','weekday_y':'weekday_test'})\n",
    "\n",
    "    #같은 station_code에서, test에는 있고 train에는 없는 weekday의 [station_code,weekday] 반환\n",
    "    dics=[]\n",
    "    staion=[]\n",
    "    for i in range(len(merged)):\n",
    "        try:\n",
    "            ls=list(set(merged['weekday_test'][i])-set(merged['weekday_train'][i]))\n",
    "            station=merged['station_code'][i]\n",
    "            if len(ls)>0:\n",
    "                dic=[station,ls]\n",
    "                dics.append(dic)\n",
    "        except:\n",
    "            dics=dics\n",
    "    \n",
    "    #dics의 [station_code,weekday]를 가진 test 데이터들을 train에 복제\n",
    "    copy_df=pd.DataFrame()\n",
    "    for i in range(len(dics)) :\n",
    "        station=dics[i][0]\n",
    "        route_id=dics[i][1]\n",
    "        df=hi_test[(hi_test['station_code']==station) & (hi_test['weekday'].isin(route_id))]\n",
    "        copy_df=pd.concat([copy_df,df])\n",
    "    hi_train=pd.concat([hi_train,copy_df])\n",
    "    return hi_train,hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bus_route_id 와 weekday로 인해 변경된 hi_train,hi_train2 를 하나로 합친후 교집합을 제거한 데이터프레임으로 재생성하기\n",
    "\n",
    "def merging_data_frame(hi):\n",
    "    hi_train,hi_test=route_copy_to_train(hi)\n",
    "    hi_train2,hi_test2=weekday_copy_to_train(hi)\n",
    "    \n",
    "    #hi_train과 hi_train2의 id값으로 merge한후 null이 없는 행은 삭제, null이 있는 행은 그대로 두고 따로 떼어낸후 concat으로 다시 붙이기\n",
    "    merged=pd.merge(hi_train,hi_train2,how='outer',on='id')\n",
    "    #id를 제외한 column에 _y 붙이기\n",
    "    columns_y=[column+'_y'if column!='id' else column for column in test_frame.columns]\n",
    "    #left 가 null\n",
    "    right=merged[merged.date_x.isnull()]\n",
    "    #id를 제외한 column에 _x 붙이기\n",
    "    columns_x=[column+'_x'if column!='id' else column for column in test_frame.columns]\n",
    "    #right 가 null\n",
    "    left=merged[merged.date_y.isnull()]\n",
    "    #inner 정리하기\n",
    "    inner=merged.dropna(axis=0)\n",
    "    inner.drop(columns=columns_y[1:],inplace=True)\n",
    "    inner.columns=test_frame.columns\n",
    "    #right 정리하기\n",
    "    right.drop(columns=columns_x[1:],inplace=True)\n",
    "    right.columns=test_frame.columns\n",
    "    #left 정리하기\n",
    "    left.drop(columns=columns_y[1:],inplace=True)\n",
    "    left.columns=test_frame.columns\n",
    "    #inner,right,left 합치기\n",
    "    hi_train3=pd.concat([inner,right,left]).reset_index(drop=True)\n",
    "    return hi_train3,hi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간략화 하기 위해 데이터 프레임에서 정류장코드 몇개만 가져오기\n",
    "\n",
    "def split(num, seed):\n",
    "    test_frame = pd.DataFrame(columns=train.columns)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for i in np.random.choice(train['station_code'].unique(), num, replace=False):\n",
    "        df1 = train[train['station_code'] == i]\n",
    "        test_frame = pd.concat([test_frame, df1])\n",
    "    return test_frame\n",
    "\n",
    "\n",
    "def ols_train_test2(test_frame, var, cate):\n",
    "    columns = test_frame.columns\n",
    "    hi_train,hi_test=merging_data_frame(test_frame)\n",
    "    df_tr = pd.DataFrame(columns=columns)\n",
    "    df_te = pd.DataFrame(columns=columns)\n",
    "    df_tr['yhat'] = 999\n",
    "    df_te['yhat'] = 999\n",
    "    cate_c = [\"C({})\".format(name) for name in cate]\n",
    "    # var_s = [f\"scale({name})\" for name in var]\n",
    "    y = ['ride18']\n",
    "\n",
    "    # 모델 학습\n",
    "    for i in test_frame['station_code'].unique():  \n",
    "        sample = hi_train[hi_train['station_code'] == i]\n",
    "        sample_model = sample[var+y+cate] # 트레인 모델\n",
    "        # 모델 포뮬라\n",
    "        model = sm.OLS.from_formula(\n",
    "        'ride18  ~ ' + '+'.join(var)\n",
    "        + '+'.join('+') + '+'.join(cate_c), data=sample_model)\n",
    "        # 학습\n",
    "        result = model.fit()\n",
    "        # 결과\n",
    "        sample['yhat'] = result.predict(sample_model)\n",
    "        sample['yhat']=[0 if yhat<0 else yhat for yhat in sample['yhat']]\n",
    "        # 학습 저장\n",
    "        df_tr = pd.concat([df_tr, sample])\n",
    "        \n",
    "        # 테스트 모델 가져오기 \n",
    "        sample2 = hi_test[hi_test['station_code'] == i]\n",
    "        sample2_model = sample2[var+cate] #테스트 모델 \n",
    "        # 테스트 모델 예측\n",
    "        sample2['yhat'] = result.predict(sample2_model)\n",
    "        sample2['yhat']=[0 if yhat<0 else yhat for yhat in sample2['yhat']]\n",
    "\n",
    "        # 테스트 저장\n",
    "        df_te = pd.concat([df_te, sample2])\n",
    "    return df_tr, df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터가 많으니, 샘플로 데이터를 뽑음 \n",
    "test_frame = split(1000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 성능 확인하기\n",
    "- 함수 'weekday_copy_to_train' 과 'merging_data_frame' 는 weekday와 weekend 카테고리 변수를 추가하기 위해 실행하는 함수이다.\n",
    "앞으로 이 두가지의 함수를 합쳐서 W함수 라고 지칭하도록 하겠다. \n",
    "- W함수를 사용하지 않은 경우에는 'ols_train_test2' 함수에서 ```hi_train,hi_test=route_copy_to_train(test_frame)``` 으로 hi_train,hi_test를 지정해주는 코드를 실행하였다. \n",
    "- test_frame의 사이즈는 위에서 확인 할 수 있듯이 1000개로 통일한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W함수사용+변수:bus_interval만 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ols 모델 돌리기\n",
    "var = ['ride6', 'ride7', 'ride8', 'ride9', 'ride10', 'ride11',\n",
    "       'off6', 'off7', 'off8', 'off9', 'off10', 'off11','bus_interval']\n",
    "# var = ['ride67', 'ride89','ride1011','off67','off89','off1011']\n",
    "cate = ['bus_route_id']\n",
    "\n",
    "df_tr, df_te = ols_train_test2(test_frame, var, cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ESS 1469031.0509741937 입니다.\n",
      "train_RSS 355284.9391052721 입니다.\n",
      "train_TSS 1841236.0686782557 입니다.\n",
      "test_ESS 656422.7218854676 입니다.\n",
      "test_RSS 234521.90510830484 입니다.\n",
      "test_TSS 771424.7120033812 입니다.\n",
      "학습 결정계수는 0.8070399851767427, 0.7978504635903358 입니다.\n",
      "검증 결정계수는 0.6959886020513213, 0.8509226003153896 입니다.\n"
     ]
    }
   ],
   "source": [
    "## R스퀘어 구하기\n",
    "# df_tr.loc[df_tr['yhat'] < 0, 'yhat'] = 0\n",
    "# df_tr['yhat'] = round(df_tr['yhat'])\n",
    "df_tr['residual'] = df_tr['ride18'] - df_tr['yhat']\n",
    "df_tr['explained'] = df_tr['yhat'] - np.mean(df_tr['yhat'])\n",
    "df_tr['total'] = df_tr['ride18'] - np.mean(df_tr['ride18'])\n",
    "\n",
    "# df_te.loc[df_te['yhat'] < 0, 'yhat'] = 0\n",
    "# df_te['yhat'] = round(df_te['yhat'])\n",
    "df_te['residual'] = df_te['ride18'] - df_te['yhat']\n",
    "df_te['explained'] = df_te['yhat'] - np.mean(df_te['yhat'])\n",
    "df_te['total'] = df_te['ride18'] - np.mean(df_te['ride18'])\n",
    "\n",
    "train_ess = np.sum((df_tr['explained'] ** 2))\n",
    "train_rss = np.sum((df_tr['residual'] ** 2))\n",
    "train_tss = np.sum((df_tr['total'] ** 2))\n",
    "\n",
    "test_ess = np.sum((df_te['explained'] ** 2))\n",
    "test_rss = np.sum((df_te['residual'] ** 2))\n",
    "test_tss = np.sum((df_te['total'] ** 2))\n",
    "\n",
    "print('train_ESS {} 입니다.'.format(train_ess))\n",
    "print('train_RSS {} 입니다.'.format(train_rss))\n",
    "print('train_TSS {} 입니다.'.format(train_tss))\n",
    "print('test_ESS {} 입니다.'.format(test_ess))\n",
    "print('test_RSS {} 입니다.'.format(test_rss))\n",
    "print('test_TSS {} 입니다.'.format(test_tss))\n",
    "print('학습 결정계수는 {}, {} 입니다.'.format(1-train_rss/train_tss, train_ess/train_tss))\n",
    "print('검증 결정계수는 {}, {} 입니다.'.format(1-test_rss/test_tss, test_ess/test_tss))\n",
    "# RMSE 예측값 - y 제곱의 평균의 루트\n",
    "# print('검증 RMSE :',np.sqrt(((df_te['yhat'] - df_te['ride18']) ** 2).mean()))\n",
    "# print('학습 RMSE :',np.sqrt(((df_tr['yhat'] - df_tr['ride18']) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W함수사용안함+변수:bus_interval만 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ols 모델 돌리기\n",
    "var = ['ride6', 'ride7', 'ride8', 'ride9', 'ride10', 'ride11',\n",
    "       'off6', 'off7', 'off8', 'off9', 'off10', 'off11','bus_interval']\n",
    "# var = ['ride67', 'ride89','ride1011','off67','off89','off1011']\n",
    "cate = ['bus_route_id']\n",
    "\n",
    "df_tr, df_te = ols_train_test2(test_frame, var, cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ESS 1675847.091795809 입니다.\n",
      "train_RSS 360752.5682889356 입니다.\n",
      "train_TSS 2052169.887446707 입니다.\n",
      "test_ESS 740141.9520817553 입니다.\n",
      "test_RSS 247566.04517691466 입니다.\n",
      "test_TSS 911196.2897084422 입니다.\n",
      "학습 결정계수는 0.824209208752312, 0.8166220068070896 입니다.\n",
      "검증 결정계수는 0.7283065701945197, 0.8122749844806549 입니다.\n"
     ]
    }
   ],
   "source": [
    "## R스퀘어 구하기\n",
    "# df_tr.loc[df_tr['yhat'] < 0, 'yhat'] = 0\n",
    "# df_tr['yhat'] = round(df_tr['yhat'])\n",
    "df_tr['residual'] = df_tr['ride18'] - df_tr['yhat']\n",
    "df_tr['explained'] = df_tr['yhat'] - np.mean(df_tr['yhat'])\n",
    "df_tr['total'] = df_tr['ride18'] - np.mean(df_tr['ride18'])\n",
    "\n",
    "# df_te.loc[df_te['yhat'] < 0, 'yhat'] = 0\n",
    "# df_te['yhat'] = round(df_te['yhat'])\n",
    "df_te['residual'] = df_te['ride18'] - df_te['yhat']\n",
    "df_te['explained'] = df_te['yhat'] - np.mean(df_te['yhat'])\n",
    "df_te['total'] = df_te['ride18'] - np.mean(df_te['ride18'])\n",
    "\n",
    "train_ess = np.sum((df_tr['explained'] ** 2))\n",
    "train_rss = np.sum((df_tr['residual'] ** 2))\n",
    "train_tss = np.sum((df_tr['total'] ** 2))\n",
    "\n",
    "test_ess = np.sum((df_te['explained'] ** 2))\n",
    "test_rss = np.sum((df_te['residual'] ** 2))\n",
    "test_tss = np.sum((df_te['total'] ** 2))\n",
    "\n",
    "print('train_ESS {} 입니다.'.format(train_ess))\n",
    "print('train_RSS {} 입니다.'.format(train_rss))\n",
    "print('train_TSS {} 입니다.'.format(train_tss))\n",
    "print('test_ESS {} 입니다.'.format(test_ess))\n",
    "print('test_RSS {} 입니다.'.format(test_rss))\n",
    "print('test_TSS {} 입니다.'.format(test_tss))\n",
    "print('학습 결정계수는 {}, {} 입니다.'.format(1-train_rss/train_tss, train_ess/train_tss))\n",
    "print('검증 결정계수는 {}, {} 입니다.'.format(1-test_rss/test_tss, test_ess/test_tss))\n",
    "# RMSE 예측값 - y 제곱의 평균의 루트\n",
    "# print('검증 RMSE :',np.sqrt(((df_te['yhat'] - df_te['ride18']) ** 2).mean()))\n",
    "# print('학습 RMSE :',np.sqrt(((df_tr['yhat'] - df_tr['ride18']) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "- 학습,검증결정계수 모두 W함수가 없는 경우가 더 좋은 것 같아 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W함수사용+모든 변수 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ols 모델 돌리기\n",
    "var = ['ride6', 'ride7', 'ride8', 'ride9', 'ride10', 'ride11',\n",
    "       'off6', 'off7', 'off8', 'off9', 'off10', 'off11',\\\n",
    "       'ride68', 'ride810', 'ride1012', 'off68', 'off810','off1012',\n",
    "       'bus_interval','temperature','precipitation']\n",
    "# var = ['ride67', 'ride89','ride1011','off67','off89','off1011']\n",
    "cate = ['bus_route_id','weekday', 'weekend', 'Thanksgiving_Day']\n",
    "\n",
    "df_tr, df_te = ols_train_test2(test_frame, var, cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ESS 1485438.852910723 입니다.\n",
      "train_RSS 316090.71308750345 입니다.\n",
      "train_TSS 1841234.629554309 입니다.\n",
      "test_ESS 713152.7399631953 입니다.\n",
      "test_RSS 256042.85629553575 입니다.\n",
      "test_TSS 771424.7120033812 입니다.\n",
      "학습 결정계수는 0.8283267607431343, 0.8067623914233515 입니다.\n",
      "검증 결정계수는 0.6680909331636585, 0.9244618805523428 입니다.\n"
     ]
    }
   ],
   "source": [
    "## R스퀘어 구하기\n",
    "# df_tr.loc[df_tr['yhat'] < 0, 'yhat'] = 0\n",
    "# df_tr['yhat'] = round(df_tr['yhat'])\n",
    "df_tr['residual'] = df_tr['ride18'] - df_tr['yhat']\n",
    "df_tr['explained'] = df_tr['yhat'] - np.mean(df_tr['yhat'])\n",
    "df_tr['total'] = df_tr['ride18'] - np.mean(df_tr['ride18'])\n",
    "\n",
    "# df_te.loc[df_te['yhat'] < 0, 'yhat'] = 0\n",
    "# df_te['yhat'] = round(df_te['yhat'])\n",
    "df_te['residual'] = df_te['ride18'] - df_te['yhat']\n",
    "df_te['explained'] = df_te['yhat'] - np.mean(df_te['yhat'])\n",
    "df_te['total'] = df_te['ride18'] - np.mean(df_te['ride18'])\n",
    "\n",
    "train_ess = np.sum((df_tr['explained'] ** 2))\n",
    "train_rss = np.sum((df_tr['residual'] ** 2))\n",
    "train_tss = np.sum((df_tr['total'] ** 2))\n",
    "\n",
    "test_ess = np.sum((df_te['explained'] ** 2))\n",
    "test_rss = np.sum((df_te['residual'] ** 2))\n",
    "test_tss = np.sum((df_te['total'] ** 2))\n",
    "\n",
    "print('train_ESS {} 입니다.'.format(train_ess))\n",
    "print('train_RSS {} 입니다.'.format(train_rss))\n",
    "print('train_TSS {} 입니다.'.format(train_tss))\n",
    "print('test_ESS {} 입니다.'.format(test_ess))\n",
    "print('test_RSS {} 입니다.'.format(test_rss))\n",
    "print('test_TSS {} 입니다.'.format(test_tss))\n",
    "print('학습 결정계수는 {}, {} 입니다.'.format(1-train_rss/train_tss, train_ess/train_tss))\n",
    "print('검증 결정계수는 {}, {} 입니다.'.format(1-test_rss/test_tss, test_ess/test_tss))\n",
    "# RMSE 예측값 - y 제곱의 평균의 루트\n",
    "#print('검증 RMSE :',np.sqrt(((df_te['yhat'] - df_te['ride18']) ** 2).mean()))\n",
    "#print('학습 RMSE :',np.sqrt(((df_tr['yhat'] - df_tr['ride18']) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "- 모든 변수를 추가했지만 학습성능에 큰 차이는 없는 듯 하다.\n",
    "- 모든 변수를 추가한 경우에는 반드시 W함수를 사용해야 하므로, W함수사용안함의 경우는 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W함수사용안함+ 변수 (weekday,weekend 뺌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ols 모델 돌리기\n",
    "var = ['ride6', 'ride7', 'ride8', 'ride9', 'ride10', 'ride11',\n",
    "       'off6', 'off7', 'off8', 'off9', 'off10', 'off11',\\\n",
    "       'ride68', 'ride810', 'ride1012', 'off68', 'off810','off1012',\n",
    "       'bus_interval','temperature','precipitation']\n",
    "cate = ['bus_route_id','Thanksgiving_Day']\n",
    "\n",
    "df_tr, df_te = ols_train_test2(test_frame, var, cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ESS 1474991.8149082025 입니다.\n",
      "train_RSS 337542.8690506036 입니다.\n",
      "train_TSS 1840962.728261804 입니다.\n",
      "test_ESS 682634.3622636378 입니다.\n",
      "test_RSS 235979.13584238544 입니다.\n",
      "test_TSS 771424.7120033812 입니다.\n",
      "학습 결정계수는 0.8166487219601105, 0.8012067774456558 입니다.\n",
      "검증 결정계수는 0.6940995897972333, 0.884900822649101 입니다.\n"
     ]
    }
   ],
   "source": [
    "## R스퀘어 구하기\n",
    "# df_tr.loc[df_tr['yhat'] < 0, 'yhat'] = 0\n",
    "# df_tr['yhat'] = round(df_tr['yhat'])\n",
    "df_tr['residual'] = df_tr['ride18'] - df_tr['yhat']\n",
    "df_tr['explained'] = df_tr['yhat'] - np.mean(df_tr['yhat'])\n",
    "df_tr['total'] = df_tr['ride18'] - np.mean(df_tr['ride18'])\n",
    "\n",
    "# df_te.loc[df_te['yhat'] < 0, 'yhat'] = 0\n",
    "# df_te['yhat'] = round(df_te['yhat'])\n",
    "df_te['residual'] = df_te['ride18'] - df_te['yhat']\n",
    "df_te['explained'] = df_te['yhat'] - np.mean(df_te['yhat'])\n",
    "df_te['total'] = df_te['ride18'] - np.mean(df_te['ride18'])\n",
    "\n",
    "train_ess = np.sum((df_tr['explained'] ** 2))\n",
    "train_rss = np.sum((df_tr['residual'] ** 2))\n",
    "train_tss = np.sum((df_tr['total'] ** 2))\n",
    "\n",
    "test_ess = np.sum((df_te['explained'] ** 2))\n",
    "test_rss = np.sum((df_te['residual'] ** 2))\n",
    "test_tss = np.sum((df_te['total'] ** 2))\n",
    "\n",
    "print('train_ESS {} 입니다.'.format(train_ess))\n",
    "print('train_RSS {} 입니다.'.format(train_rss))\n",
    "print('train_TSS {} 입니다.'.format(train_tss))\n",
    "print('test_ESS {} 입니다.'.format(test_ess))\n",
    "print('test_RSS {} 입니다.'.format(test_rss))\n",
    "print('test_TSS {} 입니다.'.format(test_tss))\n",
    "print('학습 결정계수는 {}, {} 입니다.'.format(1-train_rss/train_tss, train_ess/train_tss))\n",
    "print('검증 결정계수는 {}, {} 입니다.'.format(1-test_rss/test_tss, test_ess/test_tss))\n",
    "# RMSE 예측값 - y 제곱의 평균의 루트\n",
    "#print('검증 RMSE :',np.sqrt(((df_te['yhat'] - df_te['ride18']) ** 2).mean()))\n",
    "#print('학습 RMSE :',np.sqrt(((df_tr['yhat'] - df_tr['ride18']) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "- 검증결정계수끼리의 차이가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W함수사용+변수포함(1시간단위 ride,off 뺌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ols 모델 돌리기\n",
    "var = ['ride68', 'ride810', 'ride1012', 'off68', 'off810', 'off1012',\n",
    "       'bus_interval','temperature','precipitation']\n",
    "cate = ['bus_route_id','weekday', 'weekend', 'Thanksgiving_Day']\n",
    "\n",
    "df_tr, df_te = ols_train_test2(test_frame, var, cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ESS 1460455.301240731 입니다.\n",
      "train_RSS 342344.3603821037 입니다.\n",
      "train_TSS 1841233.1903950996 입니다.\n",
      "test_ESS 673430.1536505696 입니다.\n",
      "test_RSS 212686.58785417353 입니다.\n",
      "test_TSS 772139.875711468 입니다.\n",
      "학습 결정계수는 0.8140678963599163, 0.7931940988568321 입니다.\n",
      "검증 결정계수는 0.7245491464118479, 0.8721608284121515 입니다.\n"
     ]
    }
   ],
   "source": [
    "## R스퀘어 구하기\n",
    "# df_tr.loc[df_tr['yhat'] < 0, 'yhat'] = 0\n",
    "# df_tr['yhat'] = round(df_tr['yhat'])\n",
    "df_tr['residual'] = df_tr['ride18'] - df_tr['yhat']\n",
    "df_tr['explained'] = df_tr['yhat'] - np.mean(df_tr['yhat'])\n",
    "df_tr['total'] = df_tr['ride18'] - np.mean(df_tr['ride18'])\n",
    "\n",
    "# df_te.loc[df_te['yhat'] < 0, 'yhat'] = 0\n",
    "# df_te['yhat'] = round(df_te['yhat'])\n",
    "df_te['residual'] = df_te['ride18'] - df_te['yhat']\n",
    "df_te['explained'] = df_te['yhat'] - np.mean(df_te['yhat'])\n",
    "df_te['total'] = df_te['ride18'] - np.mean(df_te['ride18'])\n",
    "\n",
    "train_ess = np.sum((df_tr['explained'] ** 2))\n",
    "train_rss = np.sum((df_tr['residual'] ** 2))\n",
    "train_tss = np.sum((df_tr['total'] ** 2))\n",
    "\n",
    "test_ess = np.sum((df_te['explained'] ** 2))\n",
    "test_rss = np.sum((df_te['residual'] ** 2))\n",
    "test_tss = np.sum((df_te['total'] ** 2))\n",
    "\n",
    "print('train_ESS {} 입니다.'.format(train_ess))\n",
    "print('train_RSS {} 입니다.'.format(train_rss))\n",
    "print('train_TSS {} 입니다.'.format(train_tss))\n",
    "print('test_ESS {} 입니다.'.format(test_ess))\n",
    "print('test_RSS {} 입니다.'.format(test_rss))\n",
    "print('test_TSS {} 입니다.'.format(test_tss))\n",
    "print('학습 결정계수는 {}, {} 입니다.'.format(1-train_rss/train_tss, train_ess/train_tss))\n",
    "print('검증 결정계수는 {}, {} 입니다.'.format(1-test_rss/test_tss, test_ess/test_tss))\n",
    "# RMSE 예측값 - y 제곱의 평균의 루트\n",
    "#print('검증 RMSE :',np.sqrt(((df_te['yhat'] - df_te['ride18']) ** 2).mean()))\n",
    "#print('학습 RMSE :',np.sqrt(((df_tr['yhat'] - df_tr['ride18']) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "- 검증 결정 계수가 높은 편이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중간 결론\n",
    "- W함수를 사용한 경우 train에 test 데이터가 복제되는 수가 많아지기 때문에 두가지 검증결정계수의 차이가 심해진다.\n",
    "- 위 상황을 고려하고도 weekend, weekday 변수를 사용해야 하는지는 좀 더 분석해봐야 할 것 같다.\n",
    "- test_frame 의 사이즈가 전체 데이터의 사이즈와 동일해 지는 경우에는 결과가 달라질 수 있다.\n",
    "- var 변수들의 scale이 필요해보인다. \n",
    "- 어떤 변수가 유의미한지 알 수 있도록 p-value를 알면 좋을 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
